{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "\n",
    "The goal of this notebook is two-fold:\n",
    "* identify the main topics of the corpus through approach (unsupervised clustering)\n",
    "* build a text classifier based on these topics (supervised learning).\n",
    "\n",
    "### Contents\n",
    "\n",
    "__Preliminaries__\n",
    "* a. Overview of text modeling techniques\n",
    "* b. Imports\n",
    "\n",
    "__1. LDA__\n",
    "\n",
    "__2. Clustering__\n",
    "* a. Tf-Idf for Clustering\n",
    "* b. K-Means\n",
    "* c. DBSCAN\n",
    "\n",
    "__3. Topic classifier__\n",
    "\n",
    "What's next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a. Overview of text modeling techniques__\n",
    "\n",
    "* [LDA](https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0)\n",
    "\n",
    "* Clustering. In order to build clusters we have to transform our news articles into a numerical representation that models can handle. Here we go for old good tf-idf vectors (we will test more state-of-the-art techniques in the next steps). Algorithms: K-Means and DBSCAN seem like the most relevant options to begin with.\n",
    "\n",
    "* ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b. Imports__\n",
    "\n",
    "If you don't have already done so, please download NLTK WordNet models by runnung the following line:\n",
    "\n",
    "> nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr_core_news_sm loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/eva/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Classic packages\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random \n",
    "random.seed(a=2905) # set random seed \n",
    "import pickle\n",
    "\n",
    "\n",
    "# NLP packages\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "import spacy\n",
    "try: \n",
    "    print(\"fr_core_news_sm loaded\")\n",
    "    nlp = spacy.load(\"fr_core_news_sm\") # load pre-trained models for French\n",
    "except:\n",
    "    print(\"fr loaded\")\n",
    "    nlp=spacy.load('fr') # fr calls fr_core_news_sm \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# ML with sklearn\n",
    "import sklearn.cluster\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "news_df=pd.read_csv(\"./articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "\n",
    "Main idea: Each document is represented as a distribution over topics, and each topic is represented as a distribution over words.\n",
    "Here we do not set the number of topics in advance, we rather set it arbitrarily like a threshold and see if the results are relevant.\n",
    "\n",
    "Code freely adapted from this [TDS post](https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Text cleaning for LDA__\n",
    "\n",
    "* tokenize words (here using spacy parser for French)\n",
    "* lemmatize (using NLTK WordNetLemmatizer)\n",
    "* stopwords removal (using the default NLTK stopwords list for French)\n",
    "* apply pipeline on titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## spacy LDA\n",
    "\n",
    "spacy.load('fr')\n",
    "from spacy.lang.fr import French\n",
    "parser = French()\n",
    "\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/eva/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## NLTK lemmatizer\n",
    "\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word, language='french')\n",
    "\n",
    "# stopwords removal\n",
    "nltk.download('stopwords')\n",
    "fr_stop = set(nltk.corpus.stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in fr_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens  #[t.encode('utf-8') for t in tokens] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quelle', 'politique', 'étrangère']\n",
      "['heure', 'comptes']\n",
      "['dernier', 'dialogue']\n",
      "['vent', 'meilleur', 'decennie']\n",
      "['couac', 'fusion', 'matra', 'aerospatiale']\n",
      "['action', 'humanitaire', 'fatiguée']\n",
      "['tapie', 'prisonnier', 'mensonge']\n",
      "['kurdistan', 'oasis', 'enfer']\n",
      "[['tintin', 'espace'], ['suicide', 'robert', 'boulin'], ['pierre', 'contre', 'certitude'], ['otages', 'soudain', 'mercredi'], ['secret', 'planète', 'rouge']]\n",
      "[['tintin', 'espace'], ['suicide', 'robert', 'boulin'], ['pierre', 'contre', 'certitude'], ['otages', 'soudain', 'mercredi'], ['secret', 'planète', 'rouge']]\n"
     ]
    }
   ],
   "source": [
    "title_tokens = []\n",
    "text_tokens = []\n",
    "\n",
    "## Apply on titles ##\n",
    "\n",
    "for t in news_df.title:\n",
    "    tokens = prepare_text_for_lda(t)\n",
    "    title_tokens.append(tokens)\n",
    "    if random.random() >0.99:\n",
    "        print(tokens)\n",
    "        \n",
    "## Apply on titles ##\n",
    "\n",
    "for t in news_df.title:\n",
    "    tokens = prepare_text_for_lda(t)\n",
    "    text_tokens.append(tokens)\n",
    "    if random.random() >0.995:\n",
    "        print(tokens)\n",
    "        \n",
    "print(title_tokens[:5])\n",
    "print(text_tokens[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Perform LDA with Gensim__\n",
    "\n",
    "Fixage arbitraire du nombre de topics, comme on fixerait arbitrairement k dans un k-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_title = corpora.Dictionary(title_tokens)\n",
    "dic_text = corpora.Dictionary(text_tokens)\n",
    "corpus_title = [dictionary.doc2bow(token) for token in title_tokens]\n",
    "corpus_text = [dictionary.doc2bow(token) for token in text_tokens]\n",
    "\n",
    "pickle.dump(corpus_title, open('corpus_title.pkl', 'wb'))\n",
    "dictionary.save('dictionary_title.gensim')\n",
    "pickle.dump(corpus_title, open('corpus_text.pkl', 'wb'))\n",
    "dictionary.save('dictionary_text.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['espace', 'tintin', 'boulin', 'robert', 'suicide', 'certitude', 'contre', 'pierre', 'mercredi', 'otages', 'soudain', 'planète', 'rouge', 'secret', 'ammar', 'forcée', 'marche', 'champion', 'discret', 'olympique', 'quinon', 'algérie', 'faillite', 'sanglante', 'israël', 'ébranlé', 'homme', 'objets', 'ponge', 'besse', 'george', 'pourquoi', 'africain', 'longue', 'mémoire', 'malgré', 'antigone', 'benazir', 'bhutto', 'janvier', 'pakistan', 'soupçons', 'triangle', 'campagne', 'ombre', 'darwin', 'trompé', 'dayan', 'symbole', 'impopulaire', 'leader', 'pérès', 'shimon', 'ainsi', 'exclusif', 'finit', 'phnom', 'témoignage', 'explique', 'simone', 'bureau', 'informatique', 'livré', 'jérusalem', 'nouveau', 'seuls', 'chopinet', 'express', 'retrouve', 'touvier', 'tutelle', 'agent', 'fausses', 'france', 'star', 'vrais', 'complexe', 'pinochet', 'challenger', 'drame', 'beineix', 'coluche', 'nourricier', 'marchandage', 'terrorisme', 'enquête', 'reprend', 'espagne', 'goytisolo', 'sarrasin', 'attentat', 'blanco', 'carrero', 'décembre', 'avortement', 'médecins', 'peine', 'hors-la-loi', 'extraits', 'guerre', 'kippour', 'autre', 'front', 'arafat', 'intronisé', 'yasser', 'femmes', 'pouvoir', 'hearst', 'nouvel', 'patricia', 'épisode', 'appel', 'ambulance', 'feuilleton', 'dibie', 'ethnologue', 'pascal', 'tribu', 'douce', 'manifestation', 'novembre', 'retour', 'tchécoslovaquie', 'pologne', 'solidarité', 'bocaux', 'énigme', 'destin', 'sacré', 'capitalisme', 'ouvre', 'délit', 'fuite', 'ozone', 'chadli', 'joker', 'faucon', 'têtes', 'future', 'noiret', 'sacrée', 'tavernier', 'union', 'jours', 'pékin', 'tiananmen', 'droits', 'famine', 'château', 'havel', 'prison', 'vaclav', 'banqueroute', 'mathieu', 'selon', 'panne', 'revanche', 'serbes', 'chargeurs', 'réunis', 'jeune', 'envers', 'paradis', 'chine', 'liberté', 'typhon', 'enfant', 'saint-laurent', 'triste', 'burguéra', 'méthode', 'baton', 'carotte', 'couette', 'degrés', 'carthage', 'rêver', 'intemporel', 'changer', 'crise', 'japon', 'paysans', 'ploucs', 'carrefour', 'science', 'conclusion', 'heureuses', 'liaison', 'croisade', 'mafia', 'papale', 'guignols', 'au-dessus', 'force', 'concertee', 'impossible', 'recession', 'reponse', 'hamas', 'occupe', 'territoires', 'haine', 'jug', 'mille', 'normale', 'nuits', 'chiffres', 'querelle', 'masquent', 'tarifs', 'transparents', 'envahie', 'europe', 'chomage', 'capital', 'comment', 'gerer', 'image', 'mammifère', 'étonnant', 'politique', 'socialistes', 'droit', 'limit', 'amour', 'hommes', 'reperes', 'quelle', 'étrangère', 'eurosceptiques', 'montée', 'terre', 'atmosphere', 'drôle', 'progrès', 'histoire', 'négociation', 'secrète', 'carton', 'jaune', 'tapie', 'agence', 'associe', 'consigny', 'directeur', 'lundi', 'octobre', 'opera', 'publicite', 'thierry', 'bazar', 'economie', 'russie', 'compact', 'irest', 'charlot', 'nappes', 'parler', 'pouvaient', 'idylle', 'staccato', 'bourse', 'gérer', 'change', 'liberte', 'presse', 'courrier', 'lecteurs', 'spirituel', 'credit', 'encore', 'lyonnais', 'tuile', 'changé', 'découvertes', 'indispensable', 'laser', 'hermon', 'michel', 'utile', 'négliger', 'bernard', 'madagascar1853', 'justice', 'sociale', 'orgueil', 'franchise', 'heure', 'vérité', 'chaos', 'morts', 'cette', 'devon', 'victoire', 'afrique', 'continent', 'miettes', 'céline', 'l.-f.', 'amérique', 'nouvelle', 'capitaine', 'grand', 'cameroun', 'deuxième', 'cent', 'métier', 'cherchent', 'patron', 'repreneur', 'influence', 'debat', 'interdit', 'interet', 'joyaux', 'éternels', 'guiloineau', 'mandela', 'nelson', 'implacable', 'santé', 'intempéries', 'tempérées', 'carnage', 'révélations', 'renseignements', 'utiles', 'course', 'decodeurs', 'méphisto', 'evaluation', 'petit', 'sortie', 'boris', 'eltsine', 'maladie', 'dollar', 'baisse', 'gandois', 'salaires', 'dijon', 'fêtards', 'italienne', 'surmontera', 'pantomime', 'port-au-prince', 'libraires', 'impitoyable', 'univers', 'amère', 'sud-ouest', 'trêve', 'chiffre', 'retenir', 'embellie', 'flaconnage', 'blessée', 'dresde', 'licencies', 'priorite', 'reembauchage', 'salary', 'fêtard', 'vague', 'diplomate', 'quotidienne', 'failli', 'perdre', 'excès', 'royaumes', 'américain', 'etape', 'atteint', 'minitel', 'diamants', 'fantômes', 'centrale', 'combourg', 'cerise', 'elles', 'lèvres', 'chant', 'dieux', 'yakoutie', 'astérix', 'theodore', 'zeldin', 'diluée', 'epopee', 'eurotunnel', 'étreinte', 'franglais', 'lexique', 'managerial', 'eternelle', 'lumiere', 'presque', 'aéropostale', 'bouilloux', 'lafont', 'marcel', 'chante', 'toute', 'calvet', 'epuisant', 'imprecateur', 'choix', 'paris', 'bananes', 'nabab', 'island', 'kangaroo', 'revivre', 'combien', 'emploi', 'offres', 'stabilisation', 'comptes', 'légende', 'ancien', 'fremissement', 'essec', 'mardis', 'suisse', 'feuille', 'impot', 'suivez', 'départ', 'apollo', 'après', 'monde', 'juillet', 'désormais', 'misent', 'nigérians', 'vivra', 'peuple', 'répression', 'alarme', 'supprimer', 'budapest', 'parle', 'sartre', 'doute', 'semaine', 'densité', 'implantation', 'rebelle', 'clef', 'psychanalyse', 'français', 'bollardière', 'combat', 'général', 'gagne', 'gourion', 'point', 'française', 'léone', 'mazurat', 'victime', 'complexité', 'edgar', 'morin', 'economiste', 'tirez', 'chorégies', 'enjeu', 'médias', 'entre', 'quell', 'racine', 'saveurs', 'senteurs', 'chantiers', 'septennat', 'véritable', 'devant', 'inégaux', 'plaisir', 'syndic', 'apres', 'abbas', 'algerienne', 'ferhat', 'utopie', 'cable', 'menace', 'satelli', 'camp', 'horreur', 'nazi', 'tours', 'deficit', 'banlieues', 'vivier', 'suédoises', 'humanitaire', 'janina', 'ochojska', 'pédagogie', 'financier', 'client', 'culture', 'flambe', 'noumea', 'paysan', 'volant', 'verbatim', 'mutation', 'nostra', 'immigres', 'affaire', 'révélons', 'budgetaire', 'controle', 'classement', 'charismatique', 'ministre', 'premier', 'québec', 'mensonge', 'prisonnier', 'dejouany', 'examen', 'berlin', 'doigts', 'cadre', 'fiers', 'partiel', 'temp', 'charles', 'maternité', 'professeur', 'rudigoz', 'désir', 'lorsque', 'paraît', 'rebonds', 'chirac', 'miroir', 'association', 'collimateur', '-nous', 'bien-être', 'combine', 'milliard', 'langage', 'exposition', 'sortir', 'leçons', 'société', 'émissions', 'film', 'communisme', 'jurassic', 'lénine', 'colon', 'préoccupent', 'khmer', 'bagarre', 'bebes', 'budget', 'coup', 'policiers', 'écrans', 'interesse', 'supporter', 'esclave', 'martyr', 'demenager', 'suffit', 'sureffectifs', 'syndicats', 'veulent', 'petite', 'phrase', 'gustatif', 'voyage', 'françoise', 'giroud', 'tigre', 'mauvais', 'signaux', 'brevete', 'vampire', 'italie', 'moral', 'ordre', 'guide', 'quand', 'ville', 'elysée', 'étranger', 'antimissile', 'orbite', 'concert', 'virtuels', 'héritage', 'rabin', 'institutionnelle', 'trace', 'badinter', 'eichmann', 'procès', 'kennedy', 'contingent', 'o.a.s.', 'programmme', 'heures', 'américains', 'barka', 'récit', 'témoin', 'chinoise', 'culturelle', 'regard', 'révolution', 'chapeau', 'envoyés', 'spéciaux', 'jean-marie', 'vraiment', 'lama', 'steppe', 'bonne', 'volonté', 'innovatrices', 'vitamine', 'all', 'franc', 'jusqu', 'ponction', 'pourrait', 'defient', 'gouvernement', 'tourisme', 'accor', 'stratégie', \"1'europe\", 'parias', 'tziganes', 'engrenage', 'medecin', 'salle', 'irremplaçable', 'mendès', 'meurtrière', 'accord', 'renault', 'volvo', 'courant', 'internationaliste', 'elizabeth', 'taylor', 'competitivite', 'prefere', 'productivite', 'directrice', 'trois', 'costume', 'marzotto', 'philippe', 'portrait', 'séguin', 'discipline', 'inflation', 'lesfrancais', 'quiachange', 'vivre', 'mince', 'responsabilité', 'bercy', 'laisse', 'marque', 'commission', 'offensive', 'orient', 'pacifique', 'proche', 'empire', 'levant', 'soleil', 'train', 'exode', 'route', 'allemande', 'crisis', 'nouvelles', 'regles', 'sauvage', 'gage', 'tueur', 'attendent', 'islamistes', 'poids', 'golda', 'espoir', 'illusion', 'comme', 'détective', 'marguerite', 'moïse', 'opération', 'demain', 'kanaky', 'tjibaou', 'honte', 'vallée', 'lettre', 'jamais', 'yamit', 'cactus', 'sinaï', 'autres', 'jean-pierre', 'écart', 'acteur', 'désengagé', 'avril', 'financer', 'retraite', 'ambiguïtés', 'holmes', 'moines', 'sherlock', 'double', 'désastreux', 'moins', 'assassinat', 'bertrand', 'cambodge', 'goulag', 'bédouins', 'glaces', 'commando', 'suite', 'henry', 'patrick', 'lrgoun', 'décider', 'euthanasie', 'médecin', 'schwartzenberg', 'condamnation', 'appeler', 'augusto', 'cessa', 'verdict', 'shamir', 'soldat', 'seconde', 'bibliothèque', 'dumberto', 'arrive', 'pauvres', 'génocide', 'burgos', 'biafra', \"jusqu'\", 'éternité', 'parachutiste', 'guérilleros', 'téhéran', 'chute', 'strasbourg', 'cirque', 'clignancourt', 'mesrine', 'giscard', 'espagnole', 'filière', 'goldman', 'lendemains', 'boulets', 'européenne', 'khomeini', 'occident', 'trembler', 'personne', 'dernier', 'dialogue', 'bombe', 'guêpier', 'frontière', 'demission', 'dessous', 'hopitaux', 'attaque', 'corruption', 'juppe', 'confession', 'policier', 'chien', 'management', 'consulter', 'francais', 'danoise', 'mariages', 'internationale', 'multiplier', 'pression', 'cardin', 'galaxie', 'mode', 'consommation', 'reprise', 'street', 'cinéma', 'grain', 'sable', 'vatican', 'encyclopedie', 'rupture', 'immigrés', 'leurs', 'diana', 'gloire', 'decollage', 'pauvre', 'armateur', 'barraquand', 'barreur', 'bollore', 'privilegier', 'syndicat', 'bien-naître', 'islande', 'devenue', 'expansion', 'fevrier', 'generation', 'precarite', 'dictature', 'narco', 'cannabis', 'toxique', 'allege', 'chambre', 'ecolo', 'energie', 'sydney', 'siens', 'toujours', 'trahi', 'complices', 'elitisme', 'populisme', 'armée', 'decus', 'patronat', 'bretagne', 'grande', 'vendre', 'cohen', 'daniel', 'flammarion', 'nation', 'page', 'pauvretes', 'richesse', 'botanique', 'cimes', 'tropicales', 'clément', 'entourloupe', 'judiciaire', 'publication', 'aquitaine', 'benie', 'brent', 'jaffre', 'énigmes', 'empoisonné', 'parquet', 'tardif', 'libre', 'modèles', 'maître', 'roseraie', 'allemagne', 'réunie', 'humeur', 'salaud', 'touche', 'frere', 'galere', 'jacques', 'saade', 'lanterne', 'francemane', 'industrie', 'apprend', 'atlantique', 'alcatel', 'patte', 'thomson', 'velours', 'antirigueur', 'argentine', 'menem', 'revolte', 'attente', 'disaient', 'expatriez', 'bilan', 'chapier', 'laisser', 'singulier', 'pedro', 'murmure', 'bator', 'ouest', 'oulan', 'délire', 'initié', 'umberto', 'libéria', 'national', 'menacé', 'parretti', 'masque', 'plume', 'westlake', 'parti', 'pluralisme', 'adolf', 'chancelier', 'hitler', 'rescapés', 'santa', 'enfants', 'juifs', 'milliers', 'financement', 'éclaté', 'apocalypse', 'folle', 'odyssée', 'femme', 'fusil', 'journal', 'dix-huit', 'islam', 'restez', 'veille', 'bousquet', 'vraie', 'bongo', 'montre', 'février', 'palestiniens', 'réfugiés', 'reculer', 'telecom', 'aguichante', 'argent', 'rideau', 'effort', 'madame', 'prendre', 'calculez', 'chef', 'devriez', 'gagner', 'service', 'secteur', 'telecommunication', 'jospin', 'fausse', 'honkong', 'vision', 'castries', 'henri', 'regner', 'royaume', 'commerce', 'exterieur', 'reparti', 'americaines', 'negociations', 'europeenne', 'seattle', 'confidentiel', 'réponse', 'maltraitance', 'principe', 'monument', 'remords', 'fiscal', 'surplus', 'conseillera', 'waigel', 'croissance', 'mondiale', 'command', 'etranger', 'profite', 'indépendanse', 'tibet', 'législatives', 'résultat', 'fiscalite', 'promet', 'encheres', 'trouble', 'deutsche', 'sanctionne', 'telekom', 'balladur', 'devedjian', 'donne', 'hommes-femmes', 'malentendu', 'cinema', 'achetez', 'grossistes', 'sicav', 'années', 'avoir', 'olivier', 'rolin', 'agriculture', 'americains', 'raboter', 'affrontent', 'arnault', 'internet', 'pinault', 'emprunt', 'financera', 'relance', 'business', 'mediterranee', 'orientale', 'industrielle', 'production', 'rechute', 'septembre', 'publique', 'gerhard', 'impots', 'massivement', 'schroder', 'abecedaire', 'amiante', 'revolution', 'silencieuse', 'choses', 'sport', 'lionel', 'parie', 'accelere', 'decelerent', 'menage', 'record', 'baudis', 'défis', 'maison', 'restauration', 'chrono', 'convertit', 'reseau', 'antimondialisation', 'exporte', 'chrétiens', 'visage', 'joyeux', 'famille', 'confirme', 'emplois', 'suppression', 'blair', 'licencier', 'tiens', 'oestrich', 'suède', 'paritarisme', 'championne', 'banque', 'public', 'epanouissement', 'fleurs', 'plein', 'astres', 'cayrol', 'publica', 'roland', 'marocain', 'pleurent', 'protecteur', 'finale', 'rugby', 'craindre', 'petrolier', 'prochain', 'troisieme', 'platanisme', 'ravage', 'decennie', 'meilleur', 'vent', 'medef', 'cerveau', 'dependance', 'molecule', 'reduire', 'toxicomanie', 'aerospatiale', 'couac', 'fusion', 'matra', 'activite', 'hausse', 'ralentie', 'enflamme', 'istambul', 'résultats', 'perdue', 'poésie', 'retrouvée', 'action', 'bonnes', 'rentables', 'bijou', 'chaumet', 'horloges', 'offre', 'danger', 'monsieur', '-vous', 'préparez', 'alstom', 'revers', 'siemens', 'subit', 'taiwan', 'abusifs', 'licenciements', 'taxer', 'commerciaux', 'enjeux', 'gouvernementales', 'mesures', 'inquiet', 'preparation', 'reunion', 'lyonnaise', 'rappelee', 'tractebel', 'mobile', 'salon', 'aubry', 'excedent', 'contes', 'irlande', 'selftrade', 'recentrage', 'platz', 'potsdamer', 'européennes', 'ténébreuse', 'fruit', 'verts', 'algerie', 'mend', 'ingénieurs', 'mobilité', 'élèves', 'camargue', 'oustique', 'coûteuses', 'négligences', 'allie', 'bebear', 'paribas', 'aides', 'europeennes', 'recoivent', 'region', 'balise', 'chemin', 'obstacle', 'pourtant', 'débriefing', 'creent', 'departements', 'equipe', 'mondial', 'xavier', 'partner', 'controversé', 'vaccin', 'frèches', 'surprise', 'basculé', 'bouygues', 'brother', 'consultant', 'etait', 'ailleurs', 'krugman', 'ballon', 'micro', 'apôtre', 'droite', 'extrême', 'attitude', 'routards', 'bienfaits', 'cohabitation', 'coffret', 'decouvertes', 'gallimard', 'havas', 'interactive', 'larousse', 'polemique', 'prevision', 'grace', 'rayonne', 'panama', 'strategie', 'ronflement', 'spleen', 'corée', 'idéale', 'touristique', 'climat', 'deteriore', 'misere', 'tortionnaire', 'chantant', 'demissionne', 'enfance', 'pâture', 'fonctionnaires', 'nippon', 'terreur', 'chronologie', 'democratie', 'anonyme', 'passionnément', 'naître', 'indomptable', 'shanghai', 'fache', 'gastronomie', 'contrer', 'invoque', 'ciblee', 'reduction', 'reflechissons', 'examine', 'ultrasons', 'amiens', 'capitale', 'téléphonie', 'multimédia', 'position', 'prend', 'schuman', 'conduit', 'houphouët', 'bénin', 'jouent', 'regrets', 'serviteur', 'vichy', 'fatiguée', 'parrain', 'musique', 'notte', 'croatie', 'déchirure', 'enfer', 'kurdistan', 'oasis', 'contrôlé', 'dérapage', 'madrid', 'promesses', 'charité', 'ordonnée', 'coeur', 'descente', 'bluff', 'bossi', 'gadget', 'prenait', 'candidats', 'embauche', 'ordinateur', 'sélection', 'couleurs', 'press', 'primaires', 'calvaire', 'scientologue', 'inégal', 'netanyahu', 'arrivee', 'etats', 'washington', 'rwanda', 'privation', 'verite', 'néerlandais', 'cotte', 'mailles', 'après-aïdid', 'espoirs', 'somalie', 'ténus', 'chancellerie', 'inquiete', 'marches', 'caisse', 'geste', 'passant', 'profanateurs', 'figaro', 'heritiers', 'guérir', 'oncle', 'otage', 'defaisance', 'mexicaine', 'cherchez', 'indifférence', 'tollé', 'folles', 'hollywood', 'doter', 'elementaire', 'gestion', 'locale', 'organismes', 'frontieres', 'passe', 'coupable', 'forum', 'skoda', 'exploitez', 'johnny', 'malheur', 'police', 'prudence', 'reforme', 'progresse', 'seule', 'finance', 'holding', 'nettoyage', 'operation', 'cache', 'dingues', 'tendance', 'tongs', 'économie', 'lescure', 'moteur', 'nethold', 'fragiles', 'jeunes', 'rêves', 'syriens', 'consommateurs', 'marketing', 'reconcilient', 'yaourt', 'belgique', 'aussi', 'cancer', 'cigarette', 'gene', 'bénéfices', 'hezbollah', 'disney', 'television', 'harcèlement', 'prion', 'savoir', 'botte', 'hauts', 'pasqua', 'replie', 'seine', 'dingue', 'indice', 'nikkei', 'piégée', 'avocats', 'cabinet', 'crible', 'pass', 'vivants', 'farines', 'poissons', 'viande', 'zapper', 'convoite', 'wireless', 'marilyn', 'monroe', 'réussir', 'confus', 'dossier', 'charonne', 'massacre']\n"
     ]
    }
   ],
   "source": [
    "print([k for k in dic_title.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics\n",
      "(0, '0.007*\"leader\" + 0.007*\"blanco\" + 0.007*\"carrero\" + 0.007*\"avortement\"')\n",
      "(1, '0.014*\"chopinet\" + 0.007*\"seuls\" + 0.007*\"finit\" + 0.007*\"livré\"')\n",
      "(2, '0.008*\"challenger\" + 0.008*\"pinochet\" + 0.008*\"complexe\" + 0.008*\"marchandage\"')\n",
      "(3, '0.007*\"témoignage\" + 0.007*\"enquête\" + 0.007*\"reprend\" + 0.007*\"ombre\"')\n",
      "(4, '0.007*\"certitude\" + 0.007*\"robert\" + 0.007*\"contre\" + 0.007*\"pierre\"')\n",
      "(5, '0.007*\"ammar\" + 0.007*\"secret\" + 0.007*\"forcée\" + 0.007*\"attentat\"')\n",
      "(6, '0.007*\"africain\" + 0.007*\"malgré\" + 0.007*\"bhutto\" + 0.007*\"benazir\"')\n",
      "(7, '0.008*\"trompé\" + 0.008*\"dayan\" + 0.008*\"symbole\" + 0.008*\"espagne\"')\n",
      "(8, '0.008*\"janvier\" + 0.001*\"drame\" + 0.001*\"ébranlé\" + 0.001*\"quinon\"')\n",
      "(9, '0.007*\"tintin\" + 0.007*\"boulin\" + 0.007*\"espace\" + 0.007*\"discret\"')\n",
      "\n",
      "Topics\n",
      "(0, '0.013*\"chopinet\" + 0.007*\"certitude\" + 0.007*\"robert\" + 0.007*\"suicide\"')\n",
      "(1, '0.013*\"objets\" + 0.007*\"leader\" + 0.007*\"décembre\" + 0.007*\"blanco\"')\n",
      "(2, '0.007*\"rouge\" + 0.007*\"planète\" + 0.007*\"soudain\" + 0.007*\"mémoire\"')\n",
      "(3, '0.007*\"tintin\" + 0.007*\"boulin\" + 0.007*\"espace\" + 0.007*\"star\"')\n",
      "(4, '0.007*\"africain\" + 0.007*\"benazir\" + 0.007*\"antigone\" + 0.007*\"bhutto\"')\n",
      "(5, '0.008*\"pakistan\" + 0.008*\"soupçons\" + 0.008*\"triangle\" + 0.001*\"marche\"')\n",
      "(6, '0.008*\"secret\" + 0.008*\"forcée\" + 0.008*\"ammar\" + 0.001*\"marche\"')\n",
      "(7, '0.008*\"marchandage\" + 0.008*\"sanglante\" + 0.008*\"israël\" + 0.008*\"nourricier\"')\n",
      "(8, '0.007*\"témoignage\" + 0.007*\"explique\" + 0.007*\"phnom\" + 0.007*\"quinon\"')\n",
      "(9, '0.007*\"pinochet\" + 0.007*\"challenger\" + 0.007*\"tutelle\" + 0.007*\"touvier\"')\n"
     ]
    }
   ],
   "source": [
    "# get the topics! \n",
    "\n",
    "NUM_TOPICS = 10\n",
    "\n",
    "for dictionary in [dic_title, dic_text]:\n",
    "    print('\\nTopics')\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "    ldamodel.save('model5.gensim')\n",
    "    topics = ldamodel.print_topics(num_words=4)\n",
    "    for topic in topics:\n",
    "        print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Analysis__\n",
    "\n",
    "* at first sight, key words associated to the same topic do not always have much in common \n",
    "* some of the words used to define topics do not seem like relevant, high level key words\n",
    "* maybe the corpus is to small or to heterogeneous to obtain relevant topics this way!\n",
    "\n",
    "--> *Improvement ideas*\n",
    "- try clustering methods and put a word on the topics\n",
    "- improve dictionary\n",
    "- improve this first LDA model (more ideas [here](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/))\n",
    "- get more data on specific topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clustering \n",
    "\n",
    "K-Means clustering and DBSCAN with tf-idf representation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a. Build a tf-idf matrix to represent the corpus__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate CountVectorizer() \n",
    "cv=CountVectorizer() \n",
    " \n",
    "# this steps generates word counts for the words in your docs \n",
    "word_count_vector=cv.fit_transform(news_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(726, 43869)\n"
     ]
    }
   ],
   "source": [
    "print(word_count_vector.shape)\n",
    "# Houston, we have a dimensionality problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>1.022254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le</th>\n",
       "      <td>1.036419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>des</th>\n",
       "      <td>1.047896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>les</th>\n",
       "      <td>1.052235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>1.053685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>un</th>\n",
       "      <td>1.074214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>1.077181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>du</th>\n",
       "      <td>1.081649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>une</th>\n",
       "      <td>1.124338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qui</th>\n",
       "      <td>1.144795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>est</th>\n",
       "      <td>1.147980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pour</th>\n",
       "      <td>1.149576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>au</th>\n",
       "      <td>1.154380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dans</th>\n",
       "      <td>1.159207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>par</th>\n",
       "      <td>1.164057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>que</th>\n",
       "      <td>1.177108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sur</th>\n",
       "      <td>1.183698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>il</th>\n",
       "      <td>1.198686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pas</th>\n",
       "      <td>1.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ce</th>\n",
       "      <td>1.259206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plus</th>\n",
       "      <td>1.269958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>1.280828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mais</th>\n",
       "      <td>1.293660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ne</th>\n",
       "      <td>1.295507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avec</th>\n",
       "      <td>1.314164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qu</th>\n",
       "      <td>1.316049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>son</th>\n",
       "      <td>1.342820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aux</th>\n",
       "      <td>1.360415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sont</th>\n",
       "      <td>1.415140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complexus</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mirella</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mirassou</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miroiter</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compils</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compilent</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compilation</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mitraillée</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compensaient</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compensant</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mitraille</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mitraillages</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mitraillage</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mitoyen</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mitonné</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mitonne</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miti</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mites</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miséricorde</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compensera</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compenseraient</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compenserait</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistes</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mister</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miste</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missives</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missive</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compensés</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miradors</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>œuvre</th>\n",
       "      <td>6.895779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43869 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                idf_weights\n",
       "de                 1.000000\n",
       "la                 1.022254\n",
       "le                 1.036419\n",
       "des                1.047896\n",
       "les                1.052235\n",
       "et                 1.053685\n",
       "un                 1.074214\n",
       "en                 1.077181\n",
       "du                 1.081649\n",
       "une                1.124338\n",
       "qui                1.144795\n",
       "est                1.147980\n",
       "pour               1.149576\n",
       "au                 1.154380\n",
       "dans               1.159207\n",
       "par                1.164057\n",
       "que                1.177108\n",
       "sur                1.183698\n",
       "il                 1.198686\n",
       "pas                1.252101\n",
       "ce                 1.259206\n",
       "plus               1.269958\n",
       "se                 1.280828\n",
       "mais               1.293660\n",
       "ne                 1.295507\n",
       "avec               1.314164\n",
       "qu                 1.316049\n",
       "son                1.342820\n",
       "aux                1.360415\n",
       "sont               1.415140\n",
       "...                     ...\n",
       "complexus          6.895779\n",
       "mirella            6.895779\n",
       "mirassou           6.895779\n",
       "miroiter           6.895779\n",
       "compils            6.895779\n",
       "compilent          6.895779\n",
       "compilation        6.895779\n",
       "mitraillée         6.895779\n",
       "compensaient       6.895779\n",
       "compensant         6.895779\n",
       "mitraille          6.895779\n",
       "mitraillages       6.895779\n",
       "mitraillage        6.895779\n",
       "mitoyen            6.895779\n",
       "mitonné            6.895779\n",
       "mitonne            6.895779\n",
       "miti               6.895779\n",
       "mites              6.895779\n",
       "miséricorde        6.895779\n",
       "compensera         6.895779\n",
       "compenseraient     6.895779\n",
       "compenserait       6.895779\n",
       "mistes             6.895779\n",
       "mister             6.895779\n",
       "miste              6.895779\n",
       "missives           6.895779\n",
       "missive            6.895779\n",
       "compensés          6.895779\n",
       "miradors           6.895779\n",
       "œuvre              6.895779\n",
       "\n",
       "[43869 rows x 1 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print idf values \n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"]) \n",
    " \n",
    "# sort ascending \n",
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to select the words with highest tf-idf count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
